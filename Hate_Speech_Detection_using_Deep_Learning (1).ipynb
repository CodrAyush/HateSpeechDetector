{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyYF6qVouCXr"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.11' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/msys64/ucrt64/bin/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Text Pre-processing libraries\n",
        "import nltk\n",
        "import string\n",
        "import warnings\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Tensorflow imports to build the model.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vGuk1zsG190g",
        "outputId": "9945d714-be9f-4bf3-94bd-d8af7e6bffa2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Dataset - Hate Speech Detection using Deep Learning.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXytfA7f2AqA",
        "outputId": "39fcaadd-2854-4a99-fe1c-01152ed996b3"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWf4a4ck2Cqj",
        "outputId": "cd5a91b9-cd3b-4bd4-bab3-3ae33787e5bc"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "svWoChgW2E4-",
        "outputId": "f260a342-9950-487f-e40a-8f8ac1c47927"
      },
      "outputs": [],
      "source": [
        "plt.pie(df['class'].value_counts().values,\n",
        "\t\tlabels = df['class'].value_counts().index,\n",
        "\t\tautopct='%1.1f%%')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "auTM43iT2HSN",
        "outputId": "d5347409-116b-4d1e-ed44-234ff055cb84"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.11' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/msys64/ucrt64/bin/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Lower case all the words of the tweet before any preprocessing\n",
        "df['tweet'] = df['tweet'].str.lower()\n",
        "\n",
        "# Removing punctuations present in the text\n",
        "punctuations_list = string.punctuation\n",
        "def remove_punctuations(text):\n",
        "\ttemp = str.maketrans('', '', punctuations_list)\n",
        "\treturn text.translate(temp)\n",
        "\n",
        "df['tweet']= df['tweet'].apply(lambda x: remove_punctuations(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2LrsZgVl2J9D",
        "outputId": "743ee2e5-9602-46db-83f1-83dd6f002301"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "\tstop_words = stopwords.words('english')\n",
        "\n",
        "\timp_words = []\n",
        "\n",
        "\t# Storing the important words\n",
        "\tfor word in str(text).split():\n",
        "\n",
        "\t\tif word not in stop_words:\n",
        "\n",
        "\t\t\t# Let's Lemmatize the word as well\n",
        "\t\t\t# before appending to the imp_words list.\n",
        "\n",
        "\t\t\tlemmatizer = WordNetLemmatizer()\n",
        "\t\t\tlemmatizer.lemmatize(word)\n",
        "\n",
        "\t\t\timp_words.append(word)\n",
        "\n",
        "\toutput = \" \".join(imp_words)\n",
        "\n",
        "\treturn output\n",
        "\n",
        "\n",
        "df['tweet'] = df['tweet'].apply(lambda text: remove_stopwords(text))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "4DMN--KG2MeO",
        "outputId": "2dd5141c-c531-4938-a4eb-70f15659b7bf"
      },
      "outputs": [],
      "source": [
        "def plot_word_cloud(data, typ):\n",
        "  # Joining all the tweets to get the corpus\n",
        "  email_corpus = \" \".join(data['tweet'])\n",
        "\n",
        "  plt.figure(figsize = (10,10))\n",
        "\n",
        "  # Forming the word cloud\n",
        "  wc = WordCloud(max_words = 100,\n",
        "                width = 200,\n",
        "                height = 100,\n",
        "                collocations = False).generate(email_corpus)\n",
        "\n",
        "  # Plotting the wordcloud obtained above\n",
        "  plt.title(f'WordCloud for {typ} emails.', fontsize = 15)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(wc)\n",
        "  plt.show()\n",
        "  print()\n",
        "\n",
        "plot_word_cloud(df[df['class']==2], typ='Neither')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qki9mIf92PEy"
      },
      "outputs": [],
      "source": [
        "class_2 = df[df['class'] == 2]\n",
        "class_1 = df[df['class'] == 1].sample(n=3500)\n",
        "class_0 = df[df['class'] == 0]\n",
        "\n",
        "balanced_df = pd.concat([class_0, class_0, class_0, class_1, class_2], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "kBKABHI12T3J",
        "outputId": "f5c97f49-e437-4aa5-cb4e-39832b4c7527"
      },
      "outputs": [],
      "source": [
        "plt.pie(balanced_df['class'].value_counts().values,\n",
        "\t\tlabels=balanced_df['class'].value_counts().index,\n",
        "\t\tautopct='%1.1f%%')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz3DGhXx2W1l",
        "outputId": "407faa73-66e8-43b6-ae78-e2f7a4da2592"
      },
      "outputs": [],
      "source": [
        "features = balanced_df['tweet']\n",
        "target = balanced_df['class']\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(features,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\ttarget,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\ttest_size=0.2,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\trandom_state=22)\n",
        "X_train.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CWnUxso2ZQG",
        "outputId": "0eda15b8-9aa8-4d49-879e-932e0e60784a"
      },
      "outputs": [],
      "source": [
        "Y_train = pd.get_dummies(Y_train)\n",
        "Y_val = pd.get_dummies(Y_val)\n",
        "Y_train.shape, Y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ks18aSTf2be2"
      },
      "outputs": [],
      "source": [
        "max_words = 5000\n",
        "max_len = 100\n",
        "\n",
        "token = Tokenizer(num_words=max_words,\n",
        "\t\t\t\tlower=True,\n",
        "\t\t\t\tsplit=' ')\n",
        "\n",
        "token.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JmYh65Oe2d6K"
      },
      "outputs": [],
      "source": [
        "# training the tokenizer\n",
        "max_words = 5000\n",
        "token = Tokenizer(num_words=max_words,\n",
        "\t\t\t\tlower=True,\n",
        "\t\t\t\tsplit=' ')\n",
        "token.fit_on_texts(X_train)\n",
        "\n",
        "#Generating token embeddings\n",
        "Training_seq = token.texts_to_sequences(X_train)\n",
        "Training_pad = pad_sequences(Training_seq,\n",
        "\t\t\t\t\t\t\tmaxlen=50,\n",
        "\t\t\t\t\t\t\tpadding='post',\n",
        "\t\t\t\t\t\t\ttruncating='post')\n",
        "\n",
        "Testing_seq = token.texts_to_sequences(X_val)\n",
        "Testing_pad = pad_sequences(Testing_seq,\n",
        "\t\t\t\t\t\t\tmaxlen=50,\n",
        "\t\t\t\t\t\t\tpadding='post',\n",
        "\t\t\t\t\t\t\ttruncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "mHjf5qr02g2y",
        "outputId": "731b07fa-8ae4-4d74-c88e-b071f8cced86"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "\tlayers.Embedding(max_words, 32, input_length=max_len),\n",
        "\tlayers.Bidirectional(layers.LSTM(16)),\n",
        "\tlayers.Dense(512, activation='relu', kernel_regularizer='l1'),\n",
        "\tlayers.BatchNormalization(),\n",
        "\tlayers.Dropout(0.3),\n",
        "\tlayers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "\t\t\toptimizer='adam',\n",
        "\t\t\tmetrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BaoJBqX47X2d",
        "outputId": "e9dc86e2-0f02-4721-cf45-7957574214ce"
      },
      "outputs": [],
      "source": [
        "# Add a dummy input to build the model\n",
        "model.build((None, max_len))\n",
        "\n",
        "keras.utils.plot_model(\n",
        "    model,\n",
        "    show_shapes=True,\n",
        "    show_dtype=True,\n",
        "    show_layer_activations=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T52bS10t2lhE"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "es = EarlyStopping(patience=3,\n",
        "\t\t\t\tmonitor = 'val_accuracy',\n",
        "\t\t\t\trestore_best_weights = True)\n",
        "\n",
        "lr = ReduceLROnPlateau(patience = 2,\n",
        "\t\t\t\t\tmonitor = 'val_loss',\n",
        "\t\t\t\t\tfactor = 0.5,\n",
        "\t\t\t\t\tverbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVfnrkpOiWkH",
        "outputId": "41577b95-8abc-41b0-c080-7eed371f2cdc"
      },
      "outputs": [],
      "source": [
        "# Instantiate Tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "\n",
        "# Fit on training data\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "# Pad sequences for uniform length\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_val_padded = pad_sequences(X_val_seq, maxlen=max_len)\n",
        "\n",
        "# Now use X_train_padded and X_val_padded in your model.fit()\n",
        "history = model.fit(X_train_padded, Y_train,\n",
        "\t\t\t\t\tvalidation_data=(X_val_padded, Y_val),\n",
        "\t\t\t\t\tepochs=50,\n",
        "\t\t\t\t\tverbose=1,\n",
        "\t\t\t\t\tbatch_size=32,\n",
        "\t\t\t\t\tcallbacks=[lr, es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "NkXdJal72qeY",
        "outputId": "4a85573f-941a-41c7-b022-5bfe3cea371b"
      },
      "outputs": [],
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:, ['loss', 'val_loss']].plot()\n",
        "history_df.loc[:, ['accuracy', 'val_accuracy']].plot()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
